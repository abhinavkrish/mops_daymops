\section{Metrics \& Scaling of DayMOPS}

Current development efforts have focused on the sky-plane tracking
phase of DayMOPS, as all later processing is dependant on its
success. Existing orbit determination packages claim a high rate of
success for accurate Orbit Determination (OD) given a correctly-linked
track, and should correctly reject false tracks in nearly all cases
\citep{Milani2006}. As a result, we expect that the ability of the
system to successfully generate Moving Objects data products for solar
system objects given to DayMOPS will be determined primarily by the
sky-plane tracking component and its ability to send useful tracks to
OD.  We also expect the overall resource usage of the DayMOPS system
will be calculable given the runtime of the sky-plane tracking
component, the number of tracks it passes to OD, and the per-track OD
time of our OD package.  As a result, carefully studying the behavior
and output of the sky-plane linking should provide a reasonable
estimate of the resource usage of all of DayMOPS object discovery.

% NightMOPS RESOURCE USAGE?!

%% In this section, we will present metrics used to evaluate the
%% usefulness of the sky-plane tracking approach, the correctness of our
%% software implementation, and usefulness of filters. We also
%% investigate the expected resource usage of our software and expected cost
%% of performing OD on its output.

\subsection{Approximation models}

\textbf{TBD: Put Yusra's findings here, and Tim's}



\subsection{Linking Algorithms}



\subsubsection{Metrics for End-to-end Evaluation of Sky-plane Linking}
MOPS can generate a useful orbit, and thus a Moving Object, for an
object if it is observed sufficiently for OD to be performed (6
observations from at least 3 nights is the usual rule) and a track
containing those observations is correctly generated by DayMOPS and
passed to its OD phase.  An object for which such a track is generated
by DayMOPS is considered to be \textbf{found} by the DayMOPS pipeline.

Despite the best efforts of the telescope's cadence, not all objects
are observed in a manner such that they can generate an OD-worthy
track.  We refer to an object which is observed with a cadence
sufficient for an OD-worthy track as a \textbf{findable} object.  When
running simulations, determining whether or not a given object is
findable is fairly straightforward: by using \textit{a priori}
knowledge of when its simulated detections occurred, we can simply
measure the time intervals between these detections and determine
whether the time interval were sufficient for tracklet generation and
track generation.  Note that the sky-plane velocities/accelerations of
the objects are \textit{not} used in deciding whether an object is
considered findable.


To understand net cost and success of our linking, the number of
objects found and the cost of finding them is likely sufficient.
However, when measuring and optimizing the internal behavior of the
DayMOPS system, it is helpful to study the quality and quantity of the
intermediate data structures used. Thus, we present a few additional
metrics as well.

The total number of tracks or tracklets is of significant concern when
estimating the resource usage of the system.  The number of tracklets
will be a major factor in the predicting the workload of track
generation, and the number of tracks should entirely decide the size
of the workload for OD.  As such, we measure the \textbf{number of
  tracks} and \textbf{number of tracklets}.  

Correctly-linked tracks and tracklets are referred to as \textbf{true
  tracks} and \textbf{true tracklets}. We present the percentage of
tracklets and tracks which are true in our results. Note that it is
expected that multiple correctly-linked tracklets and/or tracks may be
generated for a given found object. As such, we expect the number of
true tracks and tracklets to significantly exceed the number of found
objects.  Nonetheless, we find that checking the true/false ratio of
tracklets and tracks helps to illustrate the quality of linkages used
as input to the track generation software and to OD.

%% \textbf{consider a paragraph on object coverage; we will need to
%%   update my existing code if we use it.}




\subsection{Experiments With A Simulated LSST Asteroid Detection Catalog}

To test MOPS, we generated one month of simulated asteroid detections,
based on the image cadence of the Operations Simulator (run 3.61)
between the dates 51029 and 51061, for one month of data.  Images from
around the full sky were used.  Simulated asteroid detections were
generated by applying ephemeris generation to a statistically viable
solar system model containing 11 million objects \citep{Grav2011}.
Objects which should have been visible based on their position,
magnitude, image filter, and seeing conditions for a given image were
recorded into a detection catalog.  Plausible per-image levels of
astrometric error were added to the detection locations.

\begin{figure}[ht!]
\centering
\includegraphics[scale=.7]{newIllustrations/fullSkyYear5_sourcesScatter.png}
\caption{A reduced-density plot of simulated asteroid detections
  (DiaSources) used in our simulated catalog.}
\label{diasPlot}
\end{figure}

A plot of some of the detections used in the simulation is presented
in figure \ref{diasPlot}.  As is visible in the plot, four of the
twenty-two fields had missing data due to a software error.  We expect
that the presence of this flaw in the data should not significantly
affect the conclusions reached from our experiments.









\subsubsection{Choosing the Linking Time-Window}

As expected in production, we attempted to generate tracklets between
any pair of images separated by more than 15 minutes and less than
90 minutes.  However, to speed up the track generation phase, we
attempted to link tracklets if they were separated by $\leq$ 15 days;
in production, it is expected that this number will be 30.  These
numbers should be consistently true across all experiments presented
here.


\subsubsection{Choosing Velocity and Acceleration Limits}
\label{velAccLimits}
\begin{figure}[ht!]
  \centering
  \includegraphics[width=13cm]{illustrations/mopsplots/aug2011/n_velocity.png}
  \caption{A cumulative histogram of solar solar system object
    sky-plane velocities, organized by classification.  Note that only
    the near-earth objects have higher velocities than main-belt
    asteroids.}
  \label{velSurvey}
\end{figure}

\begin{figure}[ht!]
  \centering
  \subfloat[Apparent Accelerations in Right Ascension over 15 Days]{
    \includegraphics[width=8cm]{illustrations/mopsplots/aug2011/n_accel_ra_15.png}
    }
  \subfloat[Apparent Accelerations in Right Ascension over 30 Days]{
    \includegraphics[width=8cm]{illustrations/mopsplots/aug2011/n_accel_ra_30.png}
    }

  \subfloat[Declination Apparent Accelerations in Declination over 15 Days]{
    \includegraphics[width=8cm]{illustrations/mopsplots/aug2011/n_accel_dec_15.png}
    }
  \subfloat[Declination Apparent Accelerations in Declination over 30 Days]{
    \includegraphics[width=8cm]{illustrations/mopsplots/aug2011/n_accel_dec_30.png}
    }
  \caption{Normalized histograms of sky-plane accelerations of several
    classes solar system objects in the RA and declination, with
    objects grouped by classification.  Histograms are presented for
    changes over 15 days and 30 days. The best-fit accelerations vary
    slightly given the size of the window; this is due to
    non-quadratic factors not included in the simple quadratic model.
    15 day tracking windows are used in the experiments presented in
    this document, but we expect to move to 30 day windows in the
    future.  In both cases, virtually all MBAs, and all other objects
    except NEOs, should have accelerations between -.02 and .02
    deg/day$^2$ in both axes.}
  \label{accSurvey}
\end{figure}


In order to determine reasonable limits on velocity and acceleration
of various classes of solar system objects, a survey of the solar
system model \citep{Grav2011} was conducted, see figures
\ref{velSurvey}, \ref{accSurvey} for histograms
presenting the results of these surveys.

We found that a velocity limit of .5 deg/day and an acceleration limit
.02 deg/day$^2$ would be generally sufficient.  By examining the
detections on an object-per-object basis, we calculated that among the
186,344 objects seen with proper cadence for OD, 186,209 of these
(more than 99.9\%) should generate useful tracks given these limits.

%% see mops64: /mnt/raid/jmyers/variousDensities/fullDensity/maxV.5_15days/trueTracks/*.log





\subsection{Results}

All simulations were conducted on the Gordon cluster at San Diego
Supercomputing Center.  Because of the large memory requirements for
running MOPS, the vSMP nodes were used for all stages of computation.
Except for the scaling tests, 16 threads were used for all the runs.


\begin{figure}[ht!]
\centering
\begin{tabular}{|r l|}
\hline
Number of asteroid detections: & 36,311,037 \\
Number of non-asteroid detections: & 0 \\
Average detections per night: & 1,134,719 \\
 & \\
Number of tracklets found: & 12,890,181 \\
Number of true tracklets: & 6,859,331 \\
Tracklets \% true: & 53.2\%\\
Tracklet generation time: & 4,791 sec (1.33 hours) \\
Tracklet generation memory use: & 13.7 GB  \\
 & \\
Number of tracks found: & 10,423,382 \\
Number of true tracks: & 5,779,424 \\
Track \% true: & 55.4\% \\
Track generation time: & 36,237 sec (10.1 hours) \\
Track generation memory use: & 16.2 GB \\
 & \\
Number of found objects: & 854,037 \\
Number of findable objects: & 1,128,643 \\
Found / findable: & 75.7\% \\
\hline
\end{tabular}

\caption{Results from the MOPS run without noise.  Velocity limit was .5 deg/day, acceleration limit was .02 deg/day$^2$ and the track chi squared probability limit was .9.  Note that not quite one fourth of objects which should generate plausible tracks are rejected.}
\label{oneMonth}
\end{figure}

\subsubsection{Survey Efficiency}
Figure~\ref{oneMonth} shows in-depth stats for a survey without noise.
As in all our runs, track generation is far more expensive than
tracklet generation in terms of CPU usage, but both require
substantial amounts of memory.  Also note that nearly one fourth of
the findable objects (those which should generate useful tracks) are
not found.  We expect that this is because of overly-aggressive
filtering in the chi squared probability filter.


\subsubsection{Nightly Variance in Runtime}

The cost of running MOPS depends on a variety of factors which are
largely dependent on telescope operations, such as revisit rates and
the locations of revisits.  Figure~\ref{nightlyVariance} shows some of
the 


\begin{figure}[ht!]
  \centering
  \subfloat{
    \includegraphics[width=12cm]{newIllustrations/tracklets_nightly.png}
    }
  \\
  \subfloat{
    \includegraphics[width=12cm]{newIllustrations/tracks_nightly.png}
    }

  \caption{Per-night costs of tracklet generation and track
    generation. Also, in the track generation section,
    note that because only 31 sets of nightly tracklets were
    generated, later runs had less data in their window and thus ran
    considerably faster.  This is an artifact of the experiment and
    not a meaningful trend.}
  \label{nightlyVariance}
\end{figure}


\subsubsection{Scaling on Non-Asteroid Sources}

Actual images will contain DiaSources from non-asteroid sources:
variable stars, supernova, and image processing artifacts (e.g. from
bright stars) will also be present.  Because the quality of image
processing is not known, we added non-asteroid ``noise'' detections to
images at varying rates.  At each rate, a fixed $n$ noise detections
were added to each image, with locations chosen at random.  We
successfully ran MOPS using densities as high as 5,000 non-asteroid
sources per image.  After adding 10,000 non-asteroid sources per
image, tracklet generation was possible but linking tracklets into
tracks was too slow - at over 48 hours for a single night of
searching, it exceeded the wall-clock limit on Gordon jobs.

Figure~\ref{noiseScaling_detections} shows some information about the
detection catalogs generated at each of the noise densities.  For each
of these catalogs, tracklet generation was performed for each of the
31 simulated nights of observation; results can be seen in
Figure~\ref{noiseScaling_tracklets}.  As expected, increasing numbers
of false detections lead to worse-than-linear increases in mislinkage.
This lead to worse-than-linear increases in computational costs for generating the
tracklets, both in terms of CPU and memory usage.

The tracklets generated in the tracklet generation test were used to
test scaling of track generation.  For reasons of time, we only
attempted to search for tracks starting on the first night of
observation.  Results are presented in
Figure~\ref{noiseScaling_tracks} and Figure~\ref{noiseScaling_found}.
The track generation scaled well on the additional tracklets (which
were primarily due to mislinkage).  We saw only modest increases in
the number of output tracks and runtime for linkTracklets.  Also note
that the number of objects found remained nearly constant across the
various runs.  



\begin{figure}[ht!]
\centering

\begin{tabular}{|c c c c|}
\hline
Per-Image Noise Density & Total number of detections & \% noise detections &  \\ 
0             & 36,311,037             & 0\%                          & \\
1,250         & 72,258,537             & 49.7\%          & \\
2,500         & 108,206,037            & 66.4\%          & \\ 
5,000         & 180,101,037            & 79.8\%          & \\
\hline
\end{tabular}
\caption{An overview of the detection sets used for the scaling tests on noise density.}
\label{noiseScaling_detections}
\end{figure}

\begin{figure}[ht!]
\centering

\subfloat[Number of tracklets generated at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/tracklet_num.png}}
\subfloat[Tracklet \% true at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/tracklet_true.png}}
\\
\subfloat[Tracklet generation runtimes at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/tracklet_runtime.png}}
\subfloat[Tracklet generation memory use at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/tracklet_mem.png}}

\caption{Tracklets generated at varying densities of non-asteroid
  ``noise'' sources, and corresponding compute costs.  Each data point
  represents 31 days of tracklet generation.  The same asteroid
  catalog was used for each simulation, but increasing numbers of
  ``noise'' sources were added in each simulation (see
  Figure~\ref{noiseScaling_detections}). Note that the number of
  tracklets generated, and the computational costs to find them,
  increase quickly as noise density increases. This is apparently due
  to the increase of mislinked ``false tracklets''. }
\label{noiseScaling_tracklets}
\end{figure}


\begin{figure}[ht!]
\centering

\subfloat[Number of tracks generated at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/track_num.png}}
\subfloat[Track \% true at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/track_true.png}}
\\
\subfloat[Track generation runtimes at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/track_runtime.png}}
\subfloat[Track generation memory use at various noise density levels]
{\includegraphics[width=8cm]{newIllustrations/track_mem.png}}

\caption{Tracks generated at varying densities of non-asteroid
  ``noise'' sources, and corresponding compute costs.  Detections
  catalogs with increasing numbers of noise detections
  (Figure~\ref{noiseScaling_detections}) and tracklets generated from
  these catalogs (~\ref{noiseScaling_tracklets}) were used to generate
  linkTracklets input. For reasons of time, each linkTracklets run
  attempted to find only tracks which started on the first night of
  data and ended anywhere within the first 15 days.}
\label{noiseScaling_tracks}
\end{figure}


\begin{figure}[ht!]
\centering
\begin{tabular}{|c c c|}
\hline

Noise Density & Number of Tracklets & Found Objects \\
0 & 6,312,807 & 55,982 \\
1,250 & 13,318,186 & 55,870  \\
2,500 & 25,824,121 &  55,751  \\
5,000 & 66,635,397 &  55,464  \\
\hline
\end{tabular}

\caption{Objects found by linkTracklets with varying densities of
  noise in the input catalogs.  Note that the number of objects found
  is only slightly affected by the presence of noise in the input
  catalogs.}
\label{noiseScaling_found}
\end{figure}



\subsubsection{LinkTracklets Scaling on Number of Threads}

\begin{figure}[ht!]
\centering
\includegraphics[width=16cm]{newIllustrations/linkTracklets_scaling.png}
\caption{LinkTracklets runtimes with varying numbers of threads.}
\label{threadScaling}
\end{figure}

