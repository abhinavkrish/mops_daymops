\section{DayMOPS}
\label{linking}

Sufficiently bright moving objects which are observed by the LSST
telescope will generate DiaSource detections, stored in the LSST
DiaSource detection catalog.  The LSST DiaSource detection catalog
will also hold detections from a variety of non-moving object sources,
including transient phenomena and artifacts of image processing.

The LSST DayMOPS system is responsible for finding previously unknown
moving objects within the LSST DiaSource catalog.  Due to the large
number of detections expected, and the sometimes-unpredictable
behavior of asteroids with unknown orbits, a structured and
carefully-designed system is necessary to perform this searching and
discovery in a computationally efficient manner.






\subsection{Orbits}
Heliocentric orbits describe an orbit around the Sun.  Generally,
asteroids, planets and other solar system objects follow elliptical
paths, centered on the Sun.  These paths are described (in general
practice as well as the LSST Moving Objects catalog) with a Kepler
orbit, which describes an ellipse using six parameters. 

For purposes of DayMOPS and NightMOPS, we assume that a well-fitted
Kepler orbit should be sufficient to predict the location of an object
well into the future or past.  

\textbf{TBD: Illustration of a Kepler orbit - Wikipedia has a good one.}


\subsection{Orbit Determination and The Linking Problem}
Orbit determination refers to the problem of identifying an object's
orbit given a well-spaced set of detections of that object.  The
problem of orbit determination has been studied extensively \textbf{
  CITATIONS HERE }, and several software tools exist which can, given
a set of detections, identify an orbit which could have generated them
or identify that no such orbit could exist.We entrust that a suitable
outside tool will be chosen to handle this problem.

This leads to the non-trivial problem of correctly identifying that a
set of detections belonged to an unknown object and providing these
detections (and only those detections) to an orbit determination tool.
This is the \textbf{ linking problem}.  The majority of efforts in
the DayMOPS system have been directed at constraining the number of
linkages which are passed to the orbit determination tool, and at
methods for discovering those linkages quickly.

Fortunately, existing rules of thumb and approximations of asteroid
motion can be used both to predict possible linkages, and reject those
which are obviously untenable.

\subsubsection{Linear and Quadratic Models}
In order to discover and identify new objects, astronomers have
traditionally used sky-plane approximations to predict and model the
behavior of solar system objects for which a true orbit is not yet
known.  As a general rule of thumb, objects are said to move linearly
(with a more or less fixed velocity) in RA and Dec over the course of
a single night and quadratically (having velocity and some
acceleration) in RA and Dec over the course of a month.  These are, of
course, approximations, and linear and quadratic fits will inevitably
contain some error.

Given many detections which may or may not be attributable to one or
more asteroids, these approximations are used to help determine which
detections could plausibly be linked.  If several detections over the
course of a single night do not follow a roughly linear path, we trust
that they could not have been attributable to the same object; if
several detections over the course of a month do not follow a roughly
quadratic path, we will trust that they could not be attributable to
the same object.  By ignoring the obviously implausible linkages, we
significantly reduce the number of hypothetical linkages we must
investigate.

Of course, since these are merely approximations, it is almost
inevitable that some correct linkages will be rejected.  In
particular, some near-Earth-objects (NEOs) may exhibit sky-plane
behaviour not consistent with these rules of thumb.


\subsubsection{Higher-order Sky-Plane Models}
\textbf{TBD: Tim's methods go here - the assumed topocentric distance, topocentric correction, higher-order fits}


\subsection{The Linking Pipeline}
The linking pipeline is responsible for finding sets of detections
which may be attributable to the same moving object and sending them
to the Orbit Determination stage, which will either accept them as a
true linkage with an associated orbit or reject them as incorrectly
linked.  

To deal with the scale and complexity of discovering plausible
multi-night linkages for unknown objects, the DayMOPS system is
designed as a pipeline of several stages, building increasingly
sophisticated linkages at each step until multi-night linkages
suitable for orbit determination are discovered.  Specifically, we
move from individual detections to nightly, linear \textbf{tracklets},
to eventual multi-night, quadratic \textbf{tracks} suitable for orbit
determination.  These tracks are filtered using a slightly more
sophisticated (but simpler than full orbit-space) model of asteroid
motion, to more quickly reject the (often numerous) mislinked tracks.

\textbf{TBD: Add an illustration of the various stages and a short piece of
introductory text.  Also perhaps useful: show one object's detections and its various states of linkage. (detections, tracklets, merged tracklets, track(s))}


Note that tracklets and tracks represent hypothetical linkages, many
of which may be incorrect.  A single detection may exist in several
tracklets and/or several tracks.  A given tracklet may be found in
multiple tracks.  Some detections may never be linked into any
tracklet; some tracklets will never be linked into any track.  

%The
%DayMOPS system is built using methods and algorithms intended to
%efficiently find plausible hypothetical linkages without wasting much
%computational time or storage on finding unlikely linkages.


%% TBD: Describing topocentric correction goes here?  It has to go
%% somewhere.  It is only performed on the data sent to linkTracklets,
%% but this isn't really central to understanding the vtrees algorithm
%% - though it does effect the data ``seen'' by linkTracklets
%% throughout.


\subsection{Building Tracklets}

\textbf{ possible illustration: show Dec/time for two images, then tracklets in Dec/time}

\textbf{Tracklets} are linkages between DiaSource detections occuring
within the same night. By creating tracklets, DayMOPS can find
sky-plane position and velocity estimates for sets of detections which
may belong to the same solar system objects.  The use of tracklets
also simplifies the downstream work of track generation, which
attempts to find sets of detections with a good
position/velocity/acceleration fit on the sky-plane; since tracklets
have known position and velocity, the track generation phase needs
only to find those tracklets compatible within some acceleration
factor.

Correctly-linked tracklets from a given object are needed to generate
a good track for that object and eventually discover its orbit.
However, if these useful tracklets are too deeply buried among very
large numbers of other tracklets, then the job of tracklet linking
will become extremely slow and expensive.  Generally, these other,
unwanted tracklets are false tracklets (mislinkages between detections
not attributable to the same object), though in special conditions
large numbers of correctly-linked but redundant tracklets can cause
pain as well (this will discussed in \ref{collapseTracklets}).

In order to ensure that tracklet-generating images are acquired, it is
necessary to ensure that fields of the sky are visited two or more
times within an accepted time period each night. To constrain the
number of tracklets, we impose a maximum apparent velocity on the
tracklets, and also require that sky fields be revisited within a
fairly short time period ($\leq 90$ minutes is the current rule).
Raising the maximum velocity threshold enables one to find
faster-moving objects, and raising the maximum allowed revisit time
also enables one to generate tracklets in more fields of the sky;
however, increasing either of these thresholds also increases the
search space and can significantly increase the number of mislinked
tracklets, greatly increasing the cost downstream.




\subsubsection{The findTracklets Software}

The process of initial tracklet creation is accomplished by the
findTracklets software.  Later refinement of tracklets is accomplished
by collapseTracklets and additional filters.

\subsubsubsection{Algorithm} 

The findTracklets software is responsible for finding pairs of
detections which occur within a fixed time threshold, and have
apparent velocity below a given threshold.  For a given detection and
a set of image times, one can calculate the maximum distance an object
could have travelled at each time using the velocity limit.  To find
detections with which the query detection could be linked, one can
imagine searching a circular region in the later images based on this
distance.

\begin{figure}[ht]
  \centering
    \includegraphics[width=6cm]{illustrations/findTracklets-onequery.png}
    \caption{ An example of searching for compatible second endpoints
      for a given detection.  The first detection and each of the
      second endpoints will be used to create a new tracklet.}
\label{findTrackletsIllustrated}
\end{figure}


Fortunately, this can be
accomplished in a fairly straightforward way through the use of
KD-Trees.  KD-Trees are a data structure which allows for quickly and
efficiently performing range searches on points in space
\citep{bentley_kdtrees}.  A KD-Tree-based method for building
tracklets was first contributed by Jeremy Kubica for his PhD thesis
\citep{kubica_thesis}.  For findTracklets, 2-Dimensional KD-Trees are
used, covering the space of (RA, Dec).  Given a detection and trees
containing detections from later images, we can use range searches to
quickly find nearby detections in those later images and use them for
the creation of tracklets.

\begin{figure}[ht]
\begin{algorithmic}
\REQUIRE $I$ is a set of images, each of which has an associated exposure time and contains a set of detections
\STATE \COMMENT{Create a 2D KD-Tree for each image, holding detections from that image.}
\STATE $T \gets \emptyset$
\FOR {$i \in I$}
  \STATE $t \gets$ Make2DTree$(i.detections)$
  \STATE $t.time \gets i.time$
  \STATE $T \gets T \cup \{t\}$
\ENDFOR
\STATE \COMMENT{Use these trees to discover the actual tracklets.}
\STATE $tracklets \gets \emptyset$
\FOR {$t_1 \in T$}
  \STATE $later \gets \{t_i \in T : 0 < t_i.time - t_1.time < maxDt\}$
  \FOR{$d \in t_1.detections$}
     \FOR{$t_q \in later$}
 
       \STATE \COMMENT{Use time between images and max velocity to
         calculate the max travel distance}

        \STATE $dt \gets t_q.time - t_1.time$
        \STATE $dd \gets dt * maxV$
        \STATE \COMMENT{Use KD-Tree range search to find detections within max travel distance}
        \STATE $tracklets \gets tracklets \cup t_q.$rangeSearch($d.ra, d.dec, dd$)
     \ENDFOR
   \ENDFOR
\ENDFOR
\RETURN{$tracklets$}
\end{algorithmic}

\caption{Pseudo-code for the findTracklets algorithm.  2D (RA, Dec)
  trees are created for each image; for each detection, later trees
  are searched for nearby detections. }
 \label{findTrackletsAlgorithm}
\end{figure}


Note that because the sky is a sphere, notions of ``distance'' and
``velocity'' can become slightly confusing, especially near the poles.
Fortunately, both the KD-Tree library used and the findTracklets
software are sufficiently clever to use actual great-circle distance
and velocity for their queries, so that tracklets near the poles are
not missed.  The software should also be impervious to wrap-around
errors - objects which move between, say, $359.9 \degree$ in RA and
$.01 \degree$ in RA will be detected.  The Appendix \ref{kdTreeLib}
explains the KD-Tree library used in greater detail.  

\paragraph{Code and Usage}
Aside from the KD-Tree library, findTracklets is implemented by {\tt
  findTracklets.h}, {\tt findTracklets.cc } and a command-line
interface is provided by {\tt findTrackletsMain.cc}.  When calling the
function {\tt findTracklets()} programmatically (e.g. inside an LSST
Pipeline), use an instance of the {\tt findTrackletsConfig} to set the
values of all options (including max velocity and min/max time
threshold as well as others) and pass this to the {\tt
  findTracklets()} function.  See comments in {\tt findTracklets.h}
for documentation on the {\tt findTrackletsConfig} class.  Also see
\ref{largeData} for additional information on output methods.

The command-line {\tt findTracklets} program will take command-line
flags and use them to instantiate a {\tt findTrackletsConfig} which is
then used to call the actual {\tt findTracklets()} function.  Use {\tt
  \$findTracklets -h} for an overview of the options.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%% COLLAPSE TRACKLETS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5


\subsection{Improving and Filtering Tracklets} \label{collapseTracklets}
If a field of the sky gets multiple revisits, or more than two visits
within the time window, it is possible that findTracklets will find
more than one true tracklet associated with that object.  This can
generated needless downstream work, because the number of tracklets is
larger, and if the multiple true intra-nightly tracklets are never
linked together, then useful data (additional detections of the
object) can be lost, or may need to be pieced back together later.

In particular, in ``deep drilling'' operations, the telescope will
repeatedly image the same field of sky many times in a short period.
In these fields, the number of tracklets generated for an object will
grow like $O(n^2)$ where $n$ is the number of times the object is
seen, as each possible pair of detections will be linked.  This can
generate a huge number of tracklets, making later work exceptionally,
and needlessly, difficult.

The tracklet improvement and filtering stage attempts to remedy this
problem by joining together colinear 2-detection tracklets into
higher-cardinality (3 detections or more) tracklets.


\paragraph{Special Considerations}
There is a small risk that occasionally, a true 2-detection tracklet
be merged into a larger tracklet which is mislinked.  This is rare, as
it can only occur when a true tracklet is colinear with a mislinked
tracklet, but it is not strictly impossible.



\subsubsection{The collapseTracklets Software} 

The tracklet refinement and filtering stage actually consists of
several steps, which can be iterated as necessary.  The first and most
important stage is the collapseTracklets stage, which finds roughly
colinear tracklets and merges them.  

To accomplish this, a method similar to the Hough transform is used.
An intermediate time, $t_c$ is selected (we use the average time of
the first and last detections) and use the apparent linear motion of
the tracklets to project their location at $t_c$.  We then store these
projected (RA,Dec) locations and the angle/velocity of each tracklet.
At this point, colinear tracklets should have similar positions and
motion vectors, making them easy to find.  This is accomplished with a
series of range searches, which of course can be implemented with 4-D
(RA, Dec, angle, velocity) KD-Trees.  The full pseudo-code is
presented in Figure \ref{collapseTrackletsAlgorithm}.

\begin{figure}[ht]
\begin{algorithmic}
  \REQUIRE $T$ is a set of intra-nightly tracklets, $D$ is the set of nightly detections from which $T$ was created, $range$ is a 4-tuple of tolerances for RA, Dec, angle and velocity.
  \STATE $t_c \gets midpoint(\{ d_{time} : d \in D \})$
  \FOR {$t \in T$}
    \STATE Calculate $t$'s predicted location at time $t_c$, its motion angle and velocity
  \ENDFOR
  \STATE \COMMENT{Create a 4D KD-Tree of the tracklets on their projected RA, Dec position and motion angle/velocity.}
  \STATE $tree \gets$ Make4DTree$(T)$
  \STATE $outTracklets = \emptyset$
  \FOR {$t \in T,\ t$ has not already merged with another tracklet}
    \STATE \COMMENT{Find tracklets with projected location, motion similar to that of $t$}
     \STATE $outTracklets = outTracklets \cup tree.$rangeSearch$(t_{projected\ position}, t_{angle}, t_{velocity}, range)$
  \ENDFOR
  \RETURN{$outTracklets$}
\end{algorithmic}

\caption{Pseudo-code for the collapseTracklets algorithm. A 4-D KD-Tree over RA, Dec, angle, velocity is constructed using the projected locations and motion of the tracklets.  Tracklets which are similar in this 4-D space are roughly colinear, so they are merged and written to output}

\label{collapseTrackletsAlgorithm}

\end{figure}

Currently, collapseTracklets handles wrap-around, but otherwise treats
the sky as a flat (RA, Dec) plane when calculating the projected
positions of tracklets.  This is acceptable for tracklets close to the
ecliptic, but not sufficient closer to the poles.  This should be
fixed when possible.

Because the collapseTracklets algorithm does linking in
parameter-space, it is sometimes possible that the resulting tracklets
contain detections which are not quite colinear.  Also, some tracklets
may contain a superset of the detections present in other tracklets.
To address these, additional filtering stages are present.

\paragraph{Code and Usage}
The collapseTracklets algorithm is implemented in {\tt
  collapseTracklets.h} and {\tt collapseTracklets.cc}.  A command-line
interface is implemented in {\tt collapseTrackletsMain.cc}.  Run {\tt
  collapseTracklets -h} for usage hints.

Choosing an appropriate set of thresholds for collapseTracklets may be
difficult; with variable time between images, the amount of error on
velocity may differ from tracklet to tracklet.  Other factors come
into play as well; higher thresholds will lead to more correct
linkages as well as more incorrect linkages - which, as described in
the following section, can be ``undone'' later by purifyTracklets.  We
arrived at our current thresholds through simple trial and error.

\subsubsection{Tracklet Filtering Software}
The collapseTracklets algorithm attempts linking in parameter-space;
as a result, it is possible that tracklets which are not entirely
colinear may be merged.  This can be rectified using the
purifyTracklets algorithm, which removes detections from tracklets if
they are sufficiently off the best-fit line.  

Further, it is sometimes possible that a tracklet may link together a
set of detections already present in another, higher-cardinality
tracklet.  These ``subset tracklets'' are almost universally
unhelpful, and the removeSubsets algorithm may be used to efficiently
find and remove them from the active set of tracklets.


\begin{figure}[ht!]
\begin{algorithmic}
  \REQUIRE $T$ is a set of tracklets, $rmsMax$ is a maximum root-mean
  squared residual on the tracklet's best-fit function to its
  detections

  \FOR {$t \in T$}
    \STATE $rms = RMS(t)$
    \WHILE {$rms > maxRms, |t| > 2$} 
      \STATE remove the worst-fitting detection from $t$
      \STATE $rms = RMS(t)$
    \ENDWHILE
  \ENDFOR
  \RETURN{$outTracklets$}
\end{algorithmic}

\caption{In purifyTracklets, poorly-fitted detections are ``pruned''
  from tracklets. In certain degenerate cases, we may prune tracklets
  down to only two detections, in which case the pruning is
  abandoned.}

\label{purifyTrackletsAlgorithm}

\end{figure}


The subset removal algorithm can be used for tracklets as well as
tracks.  It is presented in \ref{subsetRemoval}.


\paragraph{Code and Usage}
We should really just kill off these silly sections and condense them
somewhere; everything has a foo.cc, foo.h and fooMain.h and a USAGE
string and a command-line calling convention and a library-style
calling convention, why repeat this everywhere?



\subsection{Building Tracks}

With tracklets already assembled, we should have many linkages
representing the position, location, and velocity of the various
objects observed, as well as ``false'', mislinked tracklets.  Making
use of the quadratic approximation of motion, valid for approximately
one month, we can move a sliding window of about 30 days over the
data, looking for tracklets which could be linked by some quadratic
acceleration factor.  As we find these linkages, we will also apply
some additional filters to avoid reporting those which are considered
too implausible (this will be described in \ref{trackFilters}).

Generally, the track generation phase is the most computationally
expensive task in DayMOPS processing; note that unlike other stages,
which consider only a night's-worth of data at a time, it must
consider tracklets from many nights and find linkages between them.
This task becomes far more difficult if the number of tracklets is
very large, either because the source data was very dense or the
thresholds were set very high, or because of poor refinement/merging
of intra-nightly tracklets.  Further, the relative looseness of the
quadratic approximation and the relative scarcity of data can make
track generation yet more difficult, as many plausible tracks may be
discovered.

Fortunately, a very clever algorithm for performing this track
discovery was presented by Kubica et al. (\citet{kubica_thesis},
\citet{Kubica:2005:MTA:1081870.1081889}).  In essence, the idea behind
the algorithm is to build per-image 4D-Trees of (RA position, Dec
position, RA velocity, Dec velocity), and use these to hold the
tracklets, indexed by position/velocity.  We then imagine the KD-Trees
as hierarchical bounding boxes, and consider pairs of bounding boxes
from different nights, calculating whether they could be linked by
some acceleration factor less than our maximum acceleration threshold.
If the boxes could be linked, then a track may exist within their
contents and we continue searching bounding boxes lower in the tree
hierarchy; if not, we know that no track of interest to us could pass
through the boxes and we can abandon searching immediately.  By using
the hierarchical structure of the KD-Trees, we can avoid searching in
large areas of tracklet-space where no track could ever exist, greatly
reducing our workload.


\subsubsection{Search Pruning}
\label{searchPruning}
In the linkTracklets algorithm, all tracklets starting in a given
image are placed in a single 4D-Tree over (RA position, Dec position,
RA velocity, Dec velocity)-space.  One tree is created for each of the
images.

Each KD-Tree node can be thought of as representing a bounding box in (RA
position, Dec position, RA velocity, Dec velocity) space.  Thus, it is
possible to calculate the acceleration needed for an object in one
bounding box in one tree to reach the second bounding box in a later
tree.  Because we are generally interested in tracks which have
acceleration within a fixed range (e.g. between $>.02 deg/day^2$ and
$<-.02 deg/day^2$), we can abandon searching at a given pair of
bounding boxes if the necessary acceleration is outside our range of
interest.

The minimum and maximum acceleration connecting two bounding boxes is
currently calculated as follows:


\begin{equation}
maxAcc = \min  \left(\begin{array}{ccc} & \displaystyle \frac{Node2.maxV - Node1.minV}{dt} \\
& \displaystyle \frac{2}{dt^2} \bigg(Node2.maxP_0 - Node1.minP_0 - Node1.minV \times dt \bigg) \\
& \displaystyle \frac{2}{dt^2} \bigg(Node1.maxP_0 - Node2.minP_0 + Node2.maxV \times dt \bigg) \end{array}\right)
% & \displaystyle parentMaxAcc, \\ jeremy says this shouldn't happen, even though it's in the code
\end{equation}

\begin{equation}
minAcc  = \max  \left(\begin{array}{ccc} & \displaystyle \frac{Node2.minV - Node1.maxV}{dt},\\
& \displaystyle \frac{2}{dt^2} \bigg( Node2.minP_0 - Node1.maxP_0 - \displaystyle Node1.maxV \times dt\bigg), \\
& \displaystyle \frac{2}{dt^2} \bigg(Node1.minP_0 - Node2.maxP_0 + Node2.minV \times dt\bigg) \end{array} \right)
%   & parentMinAcc, jeremy says this shouldn't happen, even though its in the code.
\end{equation}


Note that this approach simplifies the problem by treating the sky as
a flat plane, which will be problematic near the poles.  However, the
above calculation appears to be the ``hot spot'' of the linkTracklets
algorithm and accounts for most of the computation time, and so
simplifying to reduce floating point costs greatly improves
performance.

In the code, this calculation is performed by the function 
{\tt updateAccBoundsReturnValidity} in {\tt linkTracklets.cc}.

\subsubsection{Recursive Tree-walk Using Pruning}

The linkTracklets algorithm makes use of pruning to quickly avoid
searching in areas where no track of interest could exist.  This can
be accomplished with a recursive walk over two KD-Trees representing
tracklets from different images.  As a simplified introduction to the
full algorithm, see \ref{simplifiedLinkTracklets} for a
two-tracklet-linking, ``endpoint-only'' version of the algorithm which
finds pairs of compatible tracklets on different nights.

\begin{figure}[ht!]
\begin{algorithmic}
  \REQUIRE{$nodeA$ and $nodeB$ are KD-Tree nodes which hold tracklets
    from two different images on different nights, $minAcc$ and $maxAcc$
    specify the limits of accelerations which the user finds
    interesting.}
  
  \STATE $accRange = $ min/max acceleration to move from $nodeA$ to $nodeB$
  \IF{$accRange$ does not overlap $(minAcc, maxAcc)$}
  \RETURN $\emptyset$
  \ELSE
  \IF{$nodeA$ and $nodeB$ are leaf nodes}
  
  \STATE \COMMENT{When we hit a pair of terminal nodes, and their
    acceleration bounds are interesting, then we have found a set
      of tracklets which may be sufficient to create a track.}
    
    \RETURN $\{$tryToBuildATrack($nodeA$.tracklet, $nodeB$.tracklet)$\}$
    \ELSE
    
    \STATE \COMMENT{In order to ensure that this function sees
      nodes which are roughly the same size, we choose the larger
      node and ``split'' that one, recursing on its children.}
    
    \STATE $largerNode, smallerNode \gets $orderBySize$(nodeA, nodeB)$
    \RETURN $recurse(largerNode.\text{leftChild}, smallerNode) \cup recurse(largerNode.\text{rightChild}, smallerNode)$
    \ENDIF
    \ENDIF
    
  \end{algorithmic}
  \caption{A precursor, two-tracklet version of the linkTracklets
    algorithm.  Note that if two nodes have no chance at holding a
    compatible tracklet (first ``if'' check) then their children are
    never searched; only if they may hold an interesting track are the
    children searched.  In this way, the algorithm avoids even
    examining a great number of KD-Tree node pairs and thus the pairs
    tracklets contained therein.}
  
  \label{simplifiedLinkTracklets}
\end{figure}

\paragraph{Support Tracklets, Support Nodes, and the Full LinkTracklets Algorithm}

For Orbit Determination, we require detections on at least three
nights.  The endpoint-only algorithm in \ref{simplifiedLinkTracklets}
will only attempt to find pairs of tracklets, giving tracks with only
two nights of observational data.  In practice, we seek to find tracks
with tracklets from three unique nights.  This could be accomplished
using various extensions to the endpoint-only algorithm, but it is
argued in \citet{kubica_thesis} and
\citet{Kubica:2005:MTA:1081870.1081889} that by far the most efficient
of these variants is called the algorithm called the {\bf vtrees} (for
``variable trees'') algorithm.

In the vtrees algorithm, we search for tracks with one or more
intermediate ``support'' tracklets in between the ``endpoint'' or
``model'' tracklets (the first and last tracklet).  To accomplish
this, the vtrees algorithm searches for compatible endpoint nodes as
in \ref{simplifiedLinkTracklets} but, as search progresses, maintains
a list of compatible ``support'' nodes - nodes which could hold useful
intermediate tracklets between the tracklets in the endpoint nodes.
These are filtered at each step, using the same equations presented in
section \ref{searchPruning}.  As the search descends through the
possible valid combinations of endpoint nodes, the support list is
filtered and refined.  When search terminates at a pair of leaf nodes,
the support nodes are used to find possible support tracklets.  If the
support list ever becomes empty, we can prune the searching at this
point, since we know no useful track could exist between the endpoint
nodes.

The full vtrees algorithm is presented in
Figure~\ref{linkTrackletsAlgorithm}.  This is the actual algorithm
implemented by the function {\tt doLinkingRecurse} from {\tt linkTracklets.cc}


\begin{figure}[ht!]
\begin{algorithmic}

\REQUIRE{$nodeA$ and $nodeB$ are KD-Tree nodes which hold tracklets
  from two different images on different nights, $S$ holds a series of
  nodes from images take on nights in between $nodeA.time$ and
  $nodeB.time$, $minAcc$ and $maxAcc$ specify the limits of
  accelerations which the user finds interesting.}

\STATE $accRange = $ min/max acceleration to move from $nodeA$ to $nodeB$
\IF{$accRange$ does not overlap $(minAcc, maxAcc)$}
    \RETURN $\emptyset$
  \ELSE
  
  \FOR{$supportNode \in S$}
  \IF{$supportNode$ represents an awkwardly large portion of tracklet-space relative to $nodeA$ and $nodeB$}
    \STATE replace $supportNode$ with $supportNode.rightChild$ and $supportNode.leftChild$, coming back to them later
    \ELSE
    \IF{no track with acceleration within $accRange$ could pass from $nodeA$ through $supportNode$ and into $nodeB$}
      \STATE remove $supportNode$ from $S$
    \ENDIF
  \ENDIF

  \IF{$S$ is empty}
    \RETURN $\emptyset$ \COMMENT{There is no way to build a three-tracklet track using the contents of these nodes, so abandon searching.}
  \ENDIF

  \ENDFOR
    \IF{$nodeA$ and $nodeB$ are leaf nodes}

    \STATE \COMMENT{Again, try to build a track, this time using $S$ for intermediate tracklets}

       \RETURN $\{$tryToBuildATrack($nodeA$.tracklet, $nodeB$.tracklet, $S$)$\}$
    \ELSE

       \STATE $largerNode, smallerNode \gets $orderBySize$(nodeA, nodeB)$
       \RETURN $recurse(largerNode.\text{leftChild}, smallerNode, S) \cup recurse(largerNode.\text{rightChild}, smallerNode, S)$
  \ENDIF
\ENDIF

\end{algorithmic}
\caption{The full vtrees algorithm, the actual algorithm implemented
  in linkTracklets.  At each recursion, $S$, the set of support nodes,
  is split based on the position, velocity, and acceleration range
  implied by the $nodeA$ and $nodeB$, the two endpoint nodes.  Note
  that if support nodes are periodically ``split'' and replaced with
  their chidlren if they too large relative to $nodeA$ and $nodeB$.}
 \label{linkTrackletsAlgorithm}
\end{figure}

In the algorithm, support nodes are filtered and possibly split (and
their children filtered) at each recursive step.  Choosing when to
split the support nodes is an important performance question.  If we
split too aggressively, then we will add more items to $S$ and be
required to filter a larger number of nodes at each recursion, which
will increase cost at each step.  If we rarely split support nodes too
rarely, then the support nodes may become very large relative to the
endpoint nodes and we will often find that we have some compatible
support node, and thus continue searching - even in cases where, had
we split the support nodes, we would have seen that none of the leaf
nodes held by the larger box were consistent with our
position/velocity/acceleration range.  This leads to needless
searching when we should have simply terminated.

Currently, the cutoff for splitting is based on the spatial size of
the support node relative to that of the two endpoint nodes.  First
a weighting factor, $\alpha$, is calculated:

\begin{equation}
\alpha = \frac{supportNode.time - nodeA.time}{supportNode.time - nodeB.time}
\end{equation}

We then split the node if, for \textit{any} of the spatial axes (RA position, Dec position, RA velocity, or Dec velocity):

\begin{equation}
\bigg(\frac{width(nodeA.axis)}{\alpha} + \alpha \x width(nodeB.axis)\bigg) < 4 \x width(supportNode.axis)
\end{equation}

Where $width$ is the spatial extent of the node.

The splitting and filtering of the support trees is implemented by
{\tt splitSupportRecursively} in {\tt linkTracklets.cc}.  This
function uses several helper functions, including the same {\tt
  updateAccBoundsReturnValidity} function used to check the
compatibility of endpoint nodes.


\subsubsection{Terminal Processing - Actual Track Generation}

Once a pair of endpoint tracklets and one or more support tracklets
have been found via the vtrees algorithm, we may attempt to finally
build a track from them.  This is relatively straightforward; three or
more tracklets with compatible acceleration, from three or more
nights, have already been found.  However, this acceleration factor is
rather approximate, as it is based on the position and velocity
estimate of the tracklets, not the best-fit to the detections held in
the tracklet.  Thus, at this point we actually start examining the
detections themselves.

First, we attempt to fit a simple quadratic to the detections in the
endpoint tracklets.  We reject the track if the best-fit acceleration
is too high or too low.  Next, we use the best-fit quadratic to
predict the locations of the hypothetical object at the time of each
support detection, and find those detections within some
user-specified threshold of the predicted location.  In the event that
there are multiple possible support detections at one of these image
times, the best-fitting detection is chosen.  If an insufficient
number of valid detections are found, we reject and do not build a
track.

If the nascent track has survived these initial filters, we pass it
onward to the more precise higher-order chi-squared-probability filter
described in \ref{trackFilters}.  


\subsubsection{Subtle Quirks}

\paragraph{Min-Max KD-Trees} 

\textbf{TBD}Explain why the subtlety of how we build a tree makes a
big difference.

Astrometric error on detections will affect both the position and
velocities of true tracklets.  As a result, bounding boxes must be
extended to encompass not just the tracklets which they hold, but the
surrounding error bars.  As a result, tracklet bounding boxes (KD-Tree
nodes) are extended using the following equation, where $dt$ is the
\textit{shortest} time span of any tracklet in the bounding box:

\begin{eqnarray}
minP_0 = P_0 - astrom\_err \\
maxP_0 = P_0 + astrom\_err \\
minV = (deltaP - 2\times astrom\_err)/dt  \\
maxV = (deltaP + 2\times astrom\_err /dt
\end{eqnarray}





\subsubsection{The linkTracklets Software}
Cover the code, its status, what routines do what in the psuedocode,
etc.  Also cover hotspots, sensitive areas, and parameters which have
big impacts on behavior here.


\subsection{Filtering of Tracks}
\label{trackFilters}
Some more information on implementation of Tim's fitting and
chi-squared filter and the software. Stats on ground-truth fitting,
possible needs for improvements.


\subsection{Notes on the Linking Software}

\subsubsection{Accomodations for Large Data Sets}
\label{largeData}
Over the course of our experiments, we discovered that under some
circumstances, tools may return some very large data sets - larger
than the memory available on our development machines.  Though RAM
sizes may grow over time, it is likely that DayMOPS users will
continue to experiment with increasingly dense noise or loose limits,
resulting in increasingly large numbers of tracklets or tracks.

To help deal with this problem, the {\tt  findTracklets} and
{\tt linkTracklets} functions can be configured to output their results
in various ways; they can be configured either to store their results
in memory and return them (much like a normal function call) or to
return nothing and write results directly to file.  If the user is
confident that the data set to be returned will fit in memory, the
former is more elegant, but for our experiments we always write to
file first, in case the number of tracklets or tracks discovered is
large.

The {\tt findTracklets} and {\tt linkTracklets} functions each take as
an argument an object of type {\tt findTrackletsConfig} or
{\tt linkTrackletsConfig}; each type has a public member variable
called {\tt outputMethod} which can be set.  {\tt findTracklets.h} and
{\tt linkTracklets.h} each contain enum types which can be used to set
these flags.

Dealing with larger-than-memory data sets as input to our software
tools is a more significant problem.  We generally assume that the
number of input detections will fit in memory, and that KD-Trees of
these detections will also fit in memory.  This has always been the
case, and fortunately it is easy to predict whether a set of
detections will fit in memory or not.  However, the number of
tracklets or tracks may, depending on the data and configuration of
the software, grow to be quite large, and is not trivially
predictable.  For software which uses tracklets or tracks as its input
data and operates on them in bulk (including {\tt collapseTracklets},
{\tt removeSubsets}, and {\tt linkTracklets}), this may be problematic;
see section \ref{parallelization} for more information on this
problem.




\subsection{Orbit Fitting}
\label{orbitFitting}

Orbit fitting can be accomplished using either traditional geometric
methods, where an ellipse or parabola consistent with movement in the
gravitational field of the sun is fit to the set of detections, or
with statistical ranging, where a wide range of potential orbits are
evaluated against the set of detections to search for those with
the lowest residuals. Traditional methods are typically much speedier,
and are available to LSST through the OrbFit software from Milani
\citep{Milani2006}. Statistical ranging methods are more accurate in
exploring the full range of orbital uncertainties for each object,
which can be particularly important for objects observed near 60--90
degrees from the Sun where NEO and MBA exhibit similar apparent
motions, and are available in the OpenOrb software from Granvik
\citep{OpenOrb2009}.

In general, orbit fitting is split into two conceptual pieces - an
``initial orbit determination'' stage, where approximate orbits are
calculated, and a ``differential correction'' stage, where
perturbations on the initial orbit are evaluated to find the best fit
and uncertainty. With six observations on three different nights, most
real moving objects will pass both initial orbit determination and
differential correction with an orbit accurate enough to generate
predicted positions with uncertainties of less than a few arcminutes
for the next few months \citep{basicSolarSystem}.





\subsection{Sky-Plane Motion Limits Imposed by Sky-Plane Linking Methods}

Practical considerations necessitate that we set upper bounds on
tracklet velocity and track acceleration in order to restrict the
number of potential mislinkages. Existing methods attempt to find all
tracklets or tracks within specified velocity and acceleration limits;
as velocity and acceleration limits are raised, the number of
tracklets and tracks can grow quickly.  As a result, the choice of
velocity and acceleration limits is important, as it significantly
impacts the objects found as well as the cost of running the software.

Generally, all types of solar system objects except for the fastest of
near-earth asteroids tend to have reasonably low sky-plane velocity
and acceleration. It is expected that the fastest-moving objects will
leave visible trails in images; these may be used to isolate
detections which could be attributable to fast-movers and restrict the
potential search space for linking these detections.  See section
\ref{neosTrailing} for more information on future plans for
approaching this problem.  

