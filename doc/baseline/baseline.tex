\documentclass[12pt,preprint]{aastex}
\usepackage{url}
\usepackage{natbib}
\usepackage{graphicx}
%\usepackage{subfig}
%\usepackage{fixltx2e}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% author-defined commands
\newcommand\x         {\hbox{$\times$}}
\def\mic              {\hbox{$\mu{\rm m}$}}
\def\about            {\hbox{$\sim$}}
\def\Mo               {\hbox{$M_{\odot}$}}
\def\Lo               {\hbox{$L_{\odot}$}}

%\captionsetup[figure]{labelformat=simple}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Abstract




\begin{document}

\title{Moving Object Pipeline Requirements}

\author{}

\begin{abstract}

The Moving Object Pipeline System (MOPS) has two responsibilities
within LSST Data Management.  First, it is responsible for generating
and managing the \textbf{Moving Object} data products.  The Moving
Objects are identified solar system objects (SSOs) with associated
Keplerian orbits, errors, and a detected sources assocated with those
solar system objects.  The second responsibility of the MOPS is to
predict future locations of moving objects in incoming images so that
their sources may be associated with known objects; this will reduce
the number of transient detections and prevent Alert Generation on
detections of known Solar System objects.  Design for the MOPS
component is based closely on the design of the PanSTARRS MOPS.

\end{abstract}

\tableofcontents

%\section{Science Requirements}

\section{System Design and Responsibilities}

The Moving Object Pipeline System has two main responsibilities: the
generation and maintenance of the Moving Object database, and the
prediction of known object locations which are sent to the Association
Pipeline to prevent unneccessary alerts.  In order to fulfill these
goals, the MOPS has been broken into several componenets, colloquially
known as ``DayMOPS'' and ``NightMOPS.''  Both are based on designs and
algorithms in use in the PanSTARRS MOPS system.
 

\begin{figure}[!ht]
\begin{center}
  \includegraphics[width=13cm]{illustrations/mopsWithinLsst.png}
\end{center}
\caption{ Data flow from the camera through DayMOPS to the Science
  Users and Alert Generation.  DayMOPS will build and maintain the
  Moving Objects table, NightMOPS will use the Moving Objects table to
  communicate with the Assocation Pipeline.  }
\label{mopsWithinLsst}
\end{figure}


``DayMOPS,'' so called because it processes data acquired from the
previous night in a large batch operation, is responsible for
discovering new Moving Objects in newly-acquired data, searching old
data for detections of new objects, and updating the Moving Objects
table to reflect newly-acquired data. It is also responsible for
periodically cleaning and refining the contents of the Moving Objects
table.

``NightMOPS'' is responsible for projecting the locations of known
Moving Objects in upcoming images as they are announced during
night-time operations.  If Moving Objects are observed in these
images, then the Moving Object table is modified to add these
newly-acquired detections to their associated Moving Object.

The relationship between DayMOPS, NightMOPS and the neighboring
components of the LSST Data Management system is illustrated in
figure \ref{mopsWithinLsst}.

\subsection{DayMOPS: Discovering and Managing Moving Objects}

% Illustration of DayMOPS

% sky-plane vs. orbit-space illustration

The initial task of DayMOPS is to identify unknown objects present in
images and their orbits.  To accomplish this, the system initially
finds sets of detections which follow a sky-plane path roughly
consistent with asteroid motion; these sets of detections and their
fitted paths are called \textbf{tracks}.  This same method is the
basis for asteroid discovery used in the PanSTARRS Moving Object
Pipeline System \citep{psMOPSDesign}.  A set of algorithms for the
discovery of sky-plane tracks in dense data are presented in
\citet{Kubica:2005:MTA:1081870.1081889}; these algorithms are used in
the PanSTARRS MOPS as well.  Because of the loose approximations used,
many of the tracks will be mislinkages, combining detections which are
not attributable to the same source, but virtually all objects for
which a true (correctly-linked) track could be generated will get some
correct track.  LSST Data Management has developed additional
processing phases and filters which can improve the performance of the
system and reduce the computational costs by managing the number of
untrue or redundant tracks throughout the various phases of
processing.

Once tracks are discovered, they are sent to the Orbit Determination
phase. The Orbit Determination phase takes these sets of sky-plane
detections and attempts to find a Keplerian orbit which could generate
the detections, if any exists.  This orbit is further refined, and
error bounds are established, using differential correction.  Orbit
Determination will reject many tracks as false, but should
successfully find fairly precise orbits for virtually all correctly
linked tracks.  Several methods for performing this task are known,
and several have implementations available to LSST
\citep{Milani04orbitdetermination}, \citep{Milani2006},
\citep{OpenOrb2009}, \citep{granvik_thesis}.  These orbits, and the
detections present in the track associated with that orbit, are used
to generate new Moving Objects.

\begin{figure}[h]
\begin{center}
  \includegraphics[width=11cm]{illustrations/mopsDiagram.png}
\end{center}
\caption{ Data flows into the DayMOPS pipeline and results in
  modifications of the Moving Objects table in a variety of ways,
  including attribution to known objects, a multi-stage pipeline for
  the discovery of new objects, and periodic refinements of the Moving
  Object table, such as possible merges of redundant objects or
  removal of false orbits. }
\label{mopsDiagram}
\end{figure}



As in the PanSTARRS MOPS design \citep{psMOPSDesign} the LSST's
DayMOPS is expected to perform several additional tasks to manage and
improve the Moving Objects table over time.  Attribution is the
process of identifying known objects in incoming data and adding those
detections to the correct Moving Object (this task is delegated to
NightMOPS). Similarly, Precovery is the recovery of known,
unattributed detections associated with a newly-discovered Moving
Object.  Another refinement is the merging of potentially redundant
Moving Objects.  The complete set of DayMOPS tasks and their data
flows are illustrated in figure \ref{mopsDiagram}.



\subsubsection{Building Tracklets}

% possible illustration: show Dec/time for two images, then tracklets in Dec/time

\textbf{Tracklets} are the building blocks of the sky-plane
\textbf{tracks} used by DayMOPS.  Tracklets are linkages between
DiaSource detections occuring within the same night; during this time
period, solar system object motion is linear or near-linear on the
sky. By creating tracklets, DayMOPS can find sky-plane position and
velocity estimates for sets of detections which may belong to solar
system objects.  This filters out many detections of non-solar system
objects, as they are less likely to generate tracklets.  The use of
tracklets also simplifies the downstream work of track generation,
which attempts to find sets of detections with a good
position/velocity/acceleration fit on the sky-plane; since tracklets
have known position and velocity, the track generation phase needs
only to find those tracklets compatible within some acceleration
factor.

In order to ensure that tracklet-generating images are acquired, it is
necessary to ensure that regions of the sky is visited two or more
times within an accepted time period within a night.  Currently, we
require that sky fields be revisited within a fairly short time period
($\leq 90$ minutes is the current rule) in order to constrain the
maximum apparent motion of solar system objects and thus also
constrain the number of tracklets.

The discovery of tracklets can be accomplished efficiently using
KD-Tree structures \citep{bentley_kdtrees} and methods from
\citet{kubica_thesis}.  DayMOPS will build a 2-dimensional (RA, Dec)
KD-Tree for each image, using the tree to hold the detections found in
that image.  Because KD-Trees allow quick range searches of
arbitrary-dimensional spatial data, it is possible to efficiently
perform searches over the detections to find pairs of detections
sufficiently close within time and within limits on apparent
velocity. These pairs of detections are linked to generate tracklets.
% TBD: Is this clear?!

% psuedo code?

Further refinements of tracklets are possible with additional
processing. If an object gets more than one tracklet, it is possible
to use methods similar to the Hough transform to identify and merge
these redundant tracklets into larger tracklets, improving the linear
position/velocity fits of the tracklets and reducing the number of
tracklets passed downstream.

\subsubsection{Building Tracks}

Over the course of roughly one month, solar system objects tend to
follow a roughly quadratic path on the sky-plane
\citep{kubica_thesis}.  The track generation phase of DayMOPS will
attempt to find sets of tracklets (which have position and velocity
estimates) which were observed within one month of each other and are
compatible within some sky-plane acceleration factor.  Tracks which
are suitable for generating a reasonable orbital fit are sent to the
Orbit Determination phase. 

The methods used for tracklet-to-tracklet linking are described in
\citet{kubica_thesis} and \citet{Kubica:2005:MTA:1081870.1081889}.
The methods described attempt to efficiently find sets of tracklets
which are \textit{compatible} in the sense that they could be joined
to form a track: that is, tracklets which span multiple nights and
have positions and velocities which are consistent with a fixed
acceleration.  

To perform this work efficiently, these methods use four-dimensional
KD-Trees over \textit{tracklets-space}, or (RA position, Dec position,
RA velocity, Dec velocity). One tree is created per image, and holds
each tracklet which has its first detection in that image.  A
multi-tree walk is performed using a clever algorithm, efficiently
discovering all regions of tracklet-space which could contain sets of
tracklets that are compatible, while avoiding visits to tracklet-space
regions which are not compatible and could not generate a track.  This
is performed recursively until leaf nodes of the KD-Trees are reached.

% illustration from Kubica?

When the algorithm encounters a set of leaf nodes in the KD-Trees, it
attempts to build a track using the detections held in the tracklets
at the leaf nodes.  A quadratic fit, or a higher-order fit if
possible, to the detections will be attempted.  Then a quality-of-fit
assessment is used to determine whether the track is considered
acceptably credible to pass downstream to the Orbit Determination.
Investigation into ideal quality-of-fit metrics is ongoing, but as of
this writing a filter on minimum chi-squared probability appears to be
the best option.


\subsubsection{Orbit Fitting}
\label{orbitFitting}

Orbits are 6 parameter Keplerian orbits fit to the set of
observations linked during the track building phase. The Keplerian
orbit sets tighter and more complicated constraints on the linkages
than the previous quadratic approximation to this motion, and thus
provides a final filter on linkages which can correspond to true,
physical objects. Determining the orbit (and the uncertainty in the
orbit) of each moving object also allows us to predict its position
(and the uncertainty in the position) at past or future times, as well
as providing a basic element of the characterization of each moving
object.

Orbit fitting can be accomplished using either traditional geometric
methods, where an ellipse or parabola consistent with movement in the
gravitational field of the sun is fit to the set of detections, or
with statistical ranging, where a wide range of potential orbits are
evaluated against the set of detections to search for the ones with
the lowest residuals. Traditional methods are typically much speedier,
and are available to LSST through the OrbFit software from Milani
\citep{Milani2006}. Statistical ranging methods are more accurate in
exploring the full range of orbital uncertainties for each object,
which can be particularly important for objects observed near 60--90
degrees from the Sun where NEO and MBA exhibit similar apparent
motions, and are available in the OpenOrb software from Granvik
\citep{OpenOrb2009}.

In general, orbit fitting is split into two conceptual pieces - an
``initial orbit determination'' stage, where approximate orbits are
calculated, and a ``differential orbit determination'' stage, where
perturbations on the initial orbit are evaluated to find the best fit
and uncertainty. With six observations on three different nights, most
real moving objects will pass both initial orbit determination and
differential orbit determination with an orbit accurate enough to
generate predicted positions with uncertainties of less than a few
arcminutes for the next few months \citep{basicSolarSystem}.



\subsubsection{Cadence Requirements Imposed by Sky-Plane Linking Methods}
\label{cadenceRequirements}
The multi-tiered approach we describe imposes certain requirements on
telescope cadence.  For example, we cannot generate a tracklet for an
object unless it is observed twice on a given night; a track cannot be
generated for an object unless it generates multiple tracklets within
a reasonable period of time.

Further practical considerations impose further requirements on
cadence. Even if an object is observed twice within a night, it may
not be practical to generate a tracklet for that object if the time
interval between observations is too large.  This is because within a
large time period, objects can move a significant distance, and the
search space for tracklet generation can become very large, leading to
large numbers of mislinkages.  A casual study in \citet{kubica_thesis}
and experiences related to us from work on the PanSTARRS MOPS both
state an upper time limit of 90 minutes is necessary to prevent
excessively high numbers of mislinkages. A 15-minute lower limit was
also suggested as a minimum for most objects to generate useful
apparent motion relative to astrometric errors. Similarly, the
quadratic approximation of asteroid sky-plane motion breaks down after
periods longer than roughly one month \citep{kubica_thesis}.  As a
result, it is not possible to form tracks from tracklets separated by
greater than one month of observation time.

As mentioned in \ref{orbitFitting}, it is generally held that most
orbit determination methods can generate a reliable orbit given six
detections of an object occuring on at least three distinct nights.
As a general rule, the telescope cadence will attempt to revisit
fields of sky twice on a single night within a region of time that
makes tracklet generation practical; it will then attempt to revisit
these fields again on two more nights within a span of 30 days or
less.  In this way, and objects in that field will be observed a total
of at least six times on at least three different nights, generating
three or more tracklets sufficient for linking into a track.


The current implementation of simulated telescope operations
take into account these requirements when generating simulated sets of
telescope pointings. 


\subsection{NightMOPS: Predicting Moving Object Locations}

The NightMOPS section of MOPS is responsible for predicting the
locations of known Moving Objects as images are taken, so that they
may be attributed to the known Moving Objects and removed from the set
of unknown transients detections.  This allows attribution for known
Moving Objects, improving the quality of the Moving Object data
products, and also allows the prevention of unnecessary Alerts.

Predicting the locations of objects given an orbit can be accomplished
through ephemeris calculation using existing orbit-space software
suites \citep{Milani2006}, \citep{OpenOrb2009}.  However, ephemeris
calculation can be fairly slow due for large data sets.  Because the
observations schedule for LSST will be determined dynamically, it is
necessary to generate ephemeris predictions for a large Moving Object
table in a short period of time.

% some kind of time-domain illustration?

In order to accomplish this, NightMOPS will generate ``coarse
ephemerides'' for known objects, predicting their locations at the
beginning and end of the night.  Then, when given an upcoming image
location, NightMOPS will use interpolation of the coarse ephemerides
to find objects which could feasibly be present in the upcoming
image. Precise ephemerides for just these objects will be
generated. In this way, NightMOPS will avoid the problem of generating
ephemeris for each known Moving Object for every image time.


\subsection{Implementation Status}

All software components of MOPS, with the possible exception of
initial orbit determination, differential correction, and ephemeris
generation, are expected to be completed in open-source C++ compliant
with LSST software guidelines and in LSST appropriate coding style.
These components will run inside the LSST Pipeline Framework.

Currently, the initial tracking phases of DayMOPS are implemented in
LSST-compliant C++.  The selection of an appropriate package for
initial orbit determination, least-squares linearization of orbit
fitting, and ephemeris generation is incomplete but several FORTRAN
options are available to us, some open-source.  A Python-based
implementation of NightMOPS, using the LSST Pipeline Framework, is
complete but it is currently using a closed-source ephemeris
generation tool.




\section{MOPS Metrics \& Scaling}

Current development efforts have focused on the sky-plane tracking
phase of DayMOPS, as all later processing is dependant on its
success. Existing orbit determination packages claim a high rate of
success for accurate IOD given a correctly-linked track, and should
correctly reject false tracks in nearly all cases
\citep{Milani2006}. As a result, we expect that the ability of the
system to successfully generate Moving Objects data products for solar
system objects given to DayMOPS will be determined primarily by the
sky-plane tracking component and its ability to send useful tracks to
IOD.  We also expect the overall resource usage of the DayMOPS system
will be calculable given the runtime of the sky-plane tracking
component, the number of tracks it passes to IOD, and the per-track
IOD time of our IOD package.  As a result, carefully studying the
behavior and output of the sky-plane linking should provide a
reasonable estimate of the resource usage of all of DayMOPS.

% NightMOPS RESOURCE USAGE?!

In this section, we will present metrics used to evaluate the
usefulness of the sky-plane tracking approach, the correctness of our
software implementation, and usefulness of filters. We also
investigate the total cost of running our software and expected cost
of performing IOD on its output.



\subsection{Metrics And Definitions}

\subsubsection{End-to-end evaluation of Sky-plane Linking}
MOPS can generate a useful orbit, and thus a Moving Object, for an
object if it is observed sufficiently for IOD to be performed (see
\ref{cadenceRequirements} for details) and a track containing those
observations is correctly generated by DayMOPS and passed to its IOD
phase.  An object for which such a track is generated by DayMOPS is
considered to be \textbf{found} by the DayMOPS pipeline.  

Despite the best efforts of the telescope's cadence, not all objects
are observed in a manner such that they can generate an IOD-worthy
track.  We refer to an object which is observed with a cadence
sufficient for an IOD-worthy track to be generated as a
\textbf{findable} object.  When running simulations, determining
whether an object is findable or not is fairly straightforward; by
using \textit{a priori} knowledge of when its simulated detections
occurred, we can simply measure the time between these detections and
determine whether the time intervals were sufficient for tracklet
generation and track generation.  

(\textbf{consider cutting this paragraph.}) Further, practical
considerations necessitate that we set upper bounds on tracklet
velocity and track acceleration in order to restrict the number of
potential mislinkages, which can grow quickly as velocity and
acceleration limits are raised.  This will preclude a given run of the
software from finding some objects, mainly near-earth asteroids, which
may have apparent velocity or acceleration above the specified
bounds. Findable objects which should at some point in their
observation generate a track below the velocity and acceleration
limits will be referred to as \textbf{findable-within-limits}.

\subsubsection{Studying Tracks and Tracklets}

To understand net cost and benefit of a simulation, the number of
objects found and the cost of finding them is likely sufficient.
However, when measuring and optimizing the internal behavior of the
DayMOPS system, it is helpful to study the quality and quantity of the
intermediate data structures used. As such, we have developed a
reasonable set of metrics for studying tracklets and tracks.

The total number of tracks or tracklets is of significant concern when
estimating the resource usage of the system.  The number of tracklets
will be a major factor in the predicting the workload of track
generation, and the number of tracks should entirely decide the size
of the workload for IOD.  As such, we measure the \textbf{number of
  tracks} and \textbf{number of tracklets}.

%% Correctly-linked tracks and tracklets are referred to as \textbf{true
%%   tracks} and \textbf{true tracklets}. The numbers of total true
%% tracklets and tracks, as well as the \textbf{percent true} tracklets
%% or tracks, are both of interest. Note that it is expected that
%% multiple correctly-linked tracklets and/or tracks may be generated for a
%% given found object. As such, we expect the number of true tracks and
%% tracklets to be somewhat independent of the number of found objects.

%% \textbf{consider a paragraph on object coverage; we will need to
%%   update my existing code if we use it.}




\subsection{Results From Main-Belt and Distant Object Searching On Ecliptic}

The ecliptic plane is the most densely-populated region of the sky,
and main-belt asteroids generate the vast majority of detected objects
there.  Because we expect that high density will contribute
significantly to the costs of running our software, we chose to run a
simulated one-year survey using simulated images from a section of the ecliptic.
In this way, we expect to get a worst-case measurement of resource
requirements for the linking phases of the LSST MOPS.

The survey was intended to search for main-belt asteroids, on the
expectation that if they could be found and removed the clutter of the
images would be significantly reduced, making further searching (say,
for fast-moving near earth objects) less challenging.  Further,
because our software looks for objects moving or accelerating
\textit{below} a set threshold, objects moving and accelerating more
slowly than main-belters were also found.

\subsubsection{Choosing Velocity and Acceleration Limits}

\begin{figure}[ht!]
  \begin{centering}
  \includegraphics[width=13cm]{illustrations/mopsplots/findtracklets_vel1.png}
  \end{centering}
  \label{velSurvey}
  \caption{A cumulative histogram of solar solar system object sky-plane velocities, organized by classification.  Note that only the near-earth objects have higher velocities than main-belt asteroids.}
\end{figure}

\begin{figure}[ht!]
  \begin{centering}
  \includegraphics[width=13cm]{illustrations/mopsplots/hist_accRA_sky2.png}
  \end{centering}
  \label{raAccSurvey}
  \caption{A histogram of sky-plane accelerations of solar system objects in the RA axis; objects are grouped by classification.}
\end{figure}

\begin{figure}[ht!]
  \begin{centering}
  \includegraphics[width=13cm]{illustrations/mopsplots/hist_accDec2.png}
  \end{centering}
  \label{decAccSurvey}
  \caption{A histogram of sky-plane accelerations of solar system objects in the declination axis, objects are grouped by classification.}
\end{figure}

In order to determine reasonable limits on velocity and acceleration
of main-belters as well as other objects, a survey of the solar system
model \citep{Grav2011} was conducted, see figures \ref{velSurvey}, \ref{raAccSurvey}, \ref{decAccSurvey}.  We
chose a maximum velocity limit of .75 deg/day and an acceleration
limit of .02 deg/day$^2$ as a result of this survey.

\subsubsection{About the Data}

The simulated survey was conducted using the output of a simulated
survey using the LSST Operations Simulator.  A set of fields was
chosen along the ecliptic: all fields with centers along $(-8, 8)$ in
RA and $(-7.4, 8)$ in declination were considered.  This included
images whose endpoints span a region of more than 367 square
degrees. For images of those fields, we generated ephemeris for
synthetic solar system objects which could appear in the image.  These
ephemerides were then filtered on location and magnitude based on the
filter and seeing of the images.  Astrometric error was added to these
ephemerides resulting in simulated DiaSources which were used as input
to the linking stages of MOPS.

% TBD: Do we mention the missing fields?

\subsubsection{Results}



present results on main-belt survey - found, \% true, measured or expected IOD time, etc.

\subsection{Scaling On Solar System Model Density}

present results on main-belt survey with scalind density

\begin{tabular}{|c|r|r|r|r|r|}
  \hline 
  SSM Density & \#Tracklets & \#Tracks & Linking Runtime & Track \% True  \\
  \hline
  .1         &   211,635    & 122,160   & 0:11:09            & 75.97\%   \\
  .025       &   649,907    & 401,895   & 1:01:04            & 57.94\%   \\
  .05        & 1,618,205    & 1,116,346 & 04:48:24           & 40.70\%   \\
  .75        & 2,897,291    & 2,085,296 & 12:47:56           & 32.14\%   \\
  1.0        & 4,502,224    & 3,318,420 & 27:27:27           & 26.61\%   \\
  \hline
\end{tabular}


\subsection{Scaling On Non-Solar System Detection Density}

present results from the variable noise-per-image sims

\begin{tabular}{|r|r|r|r|r|r|}
  \hline 
  \% Noise & \#Tracklets & \#Tracks  & Linking Runtime & Track \% True & Found/Findable \\
  0.0\%    &  1,618,205  & 1,116,346 & 8,413           &  40.70\%      &  94.91\%       \\
  20.63\%  & 1,947,235   & 1,127,355 & 9,996           & 40.28\%       &  94.90\%       \\
  56.51\%  & 4,107,233   & 1,202,270 & 19,321          & 50.36\%       &  94.87\%       \\
  72.21\%  & 8,693,128   & 1,361,796 & 51,008          & 33.14\%       &  94.80\%       \\
  83.87\%  & 23,989,975  & 1,951,794 & 256,565         & 22.89\%       &  94.62\%       \\
  \hline
\end{tabular}



\subsection{NightMOPS Resource Usage}

do we have any idea?  should be upper bounded by size of SSM * nights
of survey * ephemeris cost + max objects per image * num images *
ephemeris cost.
















\section{Development Plan}

Though the core algorithms of MOPS have been implemented in
LSST-appropriate style, further research and development are needed.



\subsection{Long-Term Management}

Current simulations cover fairly short time periods, putting high
focus on the problems of initial object discovery.  In the course of
the full survey, we expect that the many detected sources will be
attributed to already-discovered objects.  Because initial object
discovery phases are relatively expensive and ephemeris calculation is
relatively fast, we expect that the resource usage of the system will
decline over time, as more objects are discovered and the size of
input catalogs is reduced.

Attribution, precovery and Moving Object management and refinement of the
Moving Object table are not yet implemented in LSST-compliant software.
Developing this software should be a significant development task.
However, we hope that by using the algorithms from the PanSTARRS MOPS
we can avoid any significant research tasks.

To test this software, we will need to generate simulated input
catalogs which span longer time periods.  Accomplishing this will
require either significant compute-resources or improved tools for
generating input catalogs.



\subsection{Filtering on Trailing for Near-Earth-Object Searching}

Describe trailing, how we don't really have it yet, perhaps some
preliminary results from fast-mover searches without trailing,
afterburner appraoches, etc.

Near-Earth Objects tend to have the highest sky-plane velocity.  This
presents a significant challenge; as we increase the maximum velocity
limit of our tracklet generation, the potential for mislinkage
increases significantly, leading to higher numbers of tracklets and
increased costs.  

Fortunately, we expect that fast-moving NEOs will generate visible
trails in our images.  By requiring all tracklets to show trails
consistent with their apparent sky-plane velocity, we expect that it
will be possible to filter most false tracklet linkages, thus
rendering the problem of NEO searching manageable.

The ability to filter on trailing is dependent almost entirely on our
ability to correctly identify trails in images.  Currently, the
ability of image processing to detect trails is not established.  To
remedy this, we will need to generate simulated images which include
asteroid trails and send them to image processing; further refinement
of image processing algorithms may be necesary.



\subsection{Distribution/Parallelization of Software}

Current software implementations and simulations presented in this
document use only a single processor.  Performance has been
sufficiently fast for this to be reasonable; however, as we increase
the size of the simulated sky, it will likely become necessary to
parallelize some core algorithms.

The PanSTARRS MOPS can inform our decisions on parallelization and
distribution.  Some phases of processing are trivially parallel, such
as Initial Orbit Determination, in which the same operations are
performed to a large variety of tracks; this should be very easy to
accomplish in using LSST Pipeline Middleware.  

Other tasks will be more difficult; in distributing sky-plane linking,
PanSTARRS MOPS divides up the data by field of view and distributes
the workload along this axis.  This has the advantage of distributing
the workload in a straightforward way, but potentially generating
poorly load-balanced workloads.  We plan to investigate this method,
but leave open the possibility of attempting other approaches as well.


\bibliographystyle{apj}
\bibliography{baseline}

\end{document}
